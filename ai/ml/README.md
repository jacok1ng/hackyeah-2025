# Transport Validation Classifier

System klasyfikacji ML do walidacji czy uÅ¼ytkownik faktycznie porusza siÄ™ danym Å›rodkiem transportu publicznego na podstawie danych z sensorÃ³w.

## ðŸ“Š Dane wejÅ›ciowe

### Å¹rÃ³dÅ‚a danych
- **JourneyData**: dane z sensorÃ³w w wysokiej czÄ™stotliwoÅ›ci (~100Hz)
- **VehicleTrip**: informacje o kursach pojazdÃ³w
- **Vehicle**: typ pojazdu (autobus, tramwaj, pociÄ…g), pojemnoÅ›Ä‡

### Agregacja 100Hz â†’ 1Hz

**Surowe dane** z sensorÃ³w sÄ… agregowane do **1Hz (1 prÃ³bka/sekundÄ™)** z obliczeniem statystyk:
- **min**: wartoÅ›Ä‡ minimalna w oknie 1s
- **max**: wartoÅ›Ä‡ maksymalna w oknie 1s
- **avg**: Å›rednia w oknie 1s
- **median**: mediana w oknie 1s
- **std**: odchylenie standardowe w oknie 1s

### Features (cechy)

#### Agregowane z sensorÃ³w (kaÅ¼da ma 5 wersji: _min, _max, _avg, _median, _std):
- **GPS**: 
  - `latitude_[stat]`, `longitude_[stat]`, `altitude_[stat]`
  - `speed_[stat]`, `bearing_[stat]`
  - `accuracy_[stat]`, `vertical_accuracy_[stat]`, `satellite_count_[stat]`
- **Akcelerometr**: 
  - `acceleration_x_[stat]`, `acceleration_y_[stat]`, `acceleration_z_[stat]`
  - `linear_acceleration_x_[stat]`, `linear_acceleration_y_[stat]`, `linear_acceleration_z_[stat]`
- **Å»yroskop**: 
  - `gyroscope_x_[stat]`, `gyroscope_y_[stat]`, `gyroscope_z_[stat]`
  - `rotation_vector_x_[stat]`, `rotation_vector_y_[stat]`, `rotation_vector_z_[stat]`, `rotation_vector_w_[stat]`
- **Barometr**: `pressure_[stat]`
- **Magnitude (pochodne)**:
  - `acceleration_magnitude_[stat]`
  - `linear_acceleration_magnitude_[stat]`
  - `gyroscope_magnitude_[stat]`

**ÅÄ…cznie**: ~24 cechy Ã— 5 statystyk = **~120 cech agregowanych**

#### Rolling statistics (okno 5 prÃ³bek = 5 sekund):
- `speed_rolling_std`: odchylenie std prÄ™dkoÅ›ci w ostatnich 5s
- `speed_rolling_range`: zakres prÄ™dkoÅ›ci (max - min) w oknie
- `acceleration_rolling_std`: odchylenie std przyspieszenia w ostatnich 5s
- `bearing_change_rate`: tempo zmiany kierunku

#### Czasowe:
- `hour_of_day`: godzina (0-23)
- `day_of_week`: dzieÅ„ tygodnia (0-6)
- `is_weekend`: czy weekend (0/1)

#### Pojazd:
- `is_train`: czy pociÄ…g (0/1)
- `is_tram`: czy tramwaj (0/1)
- `is_bus`: czy autobus (0/1)
- `vehicle_capacity`: pojemnoÅ›Ä‡ pojazdu

### Label (etykieta)
- `is_valid_trip`: czy uÅ¼ytkownik faktycznie byÅ‚ w tym pojeÅºdzie (0/1)

---

## ðŸš€ UÅ¼ycie

### 1. Instalacja zaleÅ¼noÅ›ci

```bash
pip install -r ml/requirements.txt
```

### 2. Przygotowanie danych

#### Wariant A: Podstawowy (bez filtrowania GPS)

```bash
python ml/prepare_transport_validation_data.py
```

**WyjÅ›cie**: `ml/transport_validation_data.csv`

**Co robi skrypt:**
1. Pobiera wysokoczÄ™stotliwoÅ›ciowe dane z `JourneyData` + `VehicleTrip` + `Vehicle`
2. Oblicza cechy pochodne (magnitude dla xyz)
3. **Agreguje 100Hz â†’ 1Hz** z statystykami (min, max, avg, median, std)
4. Dodaje cechy czasowe (hour, day, weekend)
5. Dodaje rolling statistics (5-sekundowe okna)
6. Koduje typy pojazdÃ³w (one-hot encoding)
7. CzyÅ›ci dane (usuwa brakujÄ…ce GPS, wypeÅ‚nia medianami)
8. Zapisuje do CSV

#### Wariant B: Z filtrowaniem GPS (KNN + DBSCAN) â­ REKOMENDOWANY

```bash
python ml/prepare_transport_validation_data_filtered.py
```

**WyjÅ›cie**: `ml/transport_validation_data_filtered.csv`

**Co robi dodatkowo:**
- **Filtruje po jakoÅ›ci GPS**: usuwa punkty ze sÅ‚abym sygnaÅ‚em (accuracy > 50m, satellites < 4)
- **Wykrywa skoki GPS**: usuwa punkty z nierealistycznymi prÄ™dkoÅ›ciami (> 200 km/h)
- **DBSCAN clustering**: wykrywa i usuwa outliers GPS (punkty daleko od gÅ‚Ã³wnego klastra)
- **KNN outlier detection**: usuwa punkty niespÃ³jne z sÄ…siadami (Å›rednia odlegÅ‚oÅ›Ä‡ > 200m)

**Parametry filtrowania:**
```python
# GPS quality
min_accuracy = 50  # meters
min_satellites = 4

# GPS jumps
max_speed_kmh = 200
time_threshold_seconds = 1

# DBSCAN
eps_meters = 100  # max distance in cluster
min_samples = 3   # min points for cluster

# KNN
n_neighbors = 5
distance_threshold_meters = 200
```

**Efekt**: Usuwa ~10-30% danych, ale znaczÄ…co poprawia jakoÅ›Ä‡ (mniej szumu GPS)

#### PorÃ³wnanie wariantÃ³w (wizualizacja)

```bash
python ml/visualize_gps_filtering.py
```

**WyjÅ›cie**: Wykresy porÃ³wnujÄ…ce dane przed i po filtrowaniu:
- `gps_accuracy_comparison.png` - rozkÅ‚ad dokÅ‚adnoÅ›ci GPS
- `satellite_count_comparison.png` - liczba satelitÃ³w
- `speed_distribution_comparison.png` - rozkÅ‚ad prÄ™dkoÅ›ci (wykrycie skokÃ³w GPS)
- `data_statistics_comparison.png` - ogÃ³lne statystyki

### 3. Trening modeli

```bash
python ml/train_transport_classifier.py
```

**Modele:**
- **XGBoost Classifier**
- **LightGBM Classifier**

**WyjÅ›cia:**
- `ml/xgboost_transport_validator.json` - model XGBoost
- `ml/lightgbm_transport_validator.txt` - model LightGBM
- `ml/xgboost_feature_importance.png` - waÅ¼noÅ›Ä‡ cech (XGBoost)
- `ml/lightgbm_feature_importance.png` - waÅ¼noÅ›Ä‡ cech (LightGBM)
- `ml/xgboost_confusion_matrix.png` - macierz pomyÅ‚ek (XGBoost)
- `ml/lightgbm_confusion_matrix.png` - macierz pomyÅ‚ek (LightGBM)
- `ml/roc_curves_comparison.png` - porÃ³wnanie krzywych ROC

**Metryki:**
- Accuracy (dokÅ‚adnoÅ›Ä‡)
- Precision, Recall, F1-Score
- ROC-AUC
- Confusion Matrix

---

## ðŸ“ˆ PrzykÅ‚adowe wyniki

```
=== XGBoost Performance ===
Accuracy: 0.9245

Classification Report:
              precision    recall  f1-score   support
     Invalid       0.91      0.94      0.92       150
       Valid       0.94      0.91      0.93       170
    accuracy                           0.92       320

ROC-AUC Score: 0.9653

=== LightGBM Performance ===
Accuracy: 0.9281

Classification Report:
              precision    recall  f1-score   support
     Invalid       0.92      0.95      0.93       150
       Valid       0.95      0.92      0.93       170
    accuracy                           0.93       320

ROC-AUC Score: 0.9681
```

---

## ðŸ”§ Parametry modeli

### XGBoost
```python
max_depth: 6
learning_rate: 0.1
n_estimators: 100
subsample: 0.8
colsample_bytree: 0.8
```

### LightGBM
```python
max_depth: 6
learning_rate: 0.1
n_estimators: 100
subsample: 0.8
colsample_bytree: 0.8
```

Parametry moÅ¼na dostosowaÄ‡ w pliku `train_transport_classifier.py`.

---

## ðŸ“ Uwagi

1. **Wymagana iloÅ›Ä‡ danych**: Minimum 1000 prÃ³bek dla wiarygodnych wynikÃ³w
2. **Balance klas**: Staraj siÄ™ mieÄ‡ zbilansowane klasy (50/50 valid/invalid)
3. **Feature engineering**: MoÅ¼esz dodaÄ‡ wiÄ™cej cech pochodnych w `prepare_transport_validation_data.py`
4. **Hyperparameter tuning**: UÅ¼yj GridSearch lub Optuna do optymalizacji parametrÃ³w
5. **Cross-validation**: RozwaÅ¼ k-fold CV dla lepszej oceny modelu

---

## ðŸŽ¯ Status integracji z systemem

### âœ… Model wdroÅ¼ony (faza testowa)

Model ML jest juÅ¼ zintegrowany z systemem weryfikacji streak w `crud/user_streak.py`.

**Status:** EXPERIMENTAL - Zbieranie danych do walidacji

**DziaÅ‚anie:**
1. Przy kaÅ¼dej weryfikacji podrÃ³Å¼y uruchamiane sÄ… OBA algorytmy:
   - Rule-based (GPS proximity) â†’ wynik uÅ¼ywany
   - ML model (XGBoost/LightGBM) â†’ wynik logowany
2. Wyniki zapisywane do `ml/validation_comparison.jsonl`
3. Analiza zgodnoÅ›ci po zebraniu >1000 prÃ³bek

**SprawdÅº logi:**
```bash
# Zobacz porÃ³wnanie ML vs rule-based
cat ml/validation_comparison.jsonl | jq '.'

# Policz zgodnoÅ›Ä‡
cat ml/validation_comparison.jsonl | jq '.agreement' | grep true | wc -l
```

**Po zebraniu danych:**
```python
# Analiza wynikÃ³w
import pandas as pd
logs = pd.read_json('ml/validation_comparison.jsonl', lines=True)

print(f"Agreement rate: {logs['agreement'].mean()*100:.1f}%")
print(f"ML accuracy: {logs['ml_prediction'].mean()*100:.1f}%")
print(f"Avg confidence: {logs['ml_confidence'].mean():.3f}")
```

---

## ðŸš€ PRZYSZÅOÅšÄ†: Model Transformer (REKOMENDOWANY)

### Dlaczego Transformer?

**Obecne ograniczenia (XGBoost/LightGBM):**
- âŒ Wymaga agregacji 100Hz â†’ 1Hz (utrata informacji)
- âŒ Manual feature engineering
- âŒ Nie rozumie peÅ‚nego kontekstu czasowego
- âŒ Trudna rozbudowa o nowe tryby transportu

**Zalety Transformera:**
- âœ… **Attention mechanism**: Automatycznie skupia siÄ™ na waÅ¼nych momentach (przystanki, zakrÄ™ty)
- âœ… **Surowe sekwencje**: Przetwarza 100Hz bez agregacji
- âœ… **Lepsze rozumienie czasowe**: Widzi caÅ‚Ä… podrÃ³Å¼ naraz
- âœ… **Brak feature engineering**: Sam uczy siÄ™ optymalnych cech

### Rozbudowa: Klasyfikacja Multi-Modal + Gratyfikacja Eko-MobilnoÅ›ci

**CEL:** Rozpoznawanie WSZYSTKICH Å›rodkÃ³w transportu uÅ¼ytkownika

```
Input: Surowe dane sensorowe (GPS, akcelerometr, Å¼yroskop)
Output: Typ transportu + pewnoÅ›Ä‡

Klasy:
- ðŸšŒ Autobus        (eco_points: 75)
- ðŸšŠ Tramwaj        (eco_points: 80)
- ðŸš† PociÄ…g         (eco_points: 75)
- ðŸš‡ Metro          (eco_points: 70)
- ðŸš— SamochÃ³d (k)   (eco_points: 10)
- ðŸš™ SamochÃ³d (p)   (eco_points: 30)
- ðŸš´ Rower          (eco_points: 90)
- ðŸ›´ Hulajnoga e.   (eco_points: 60)
- ðŸš¶ Pieszo         (eco_points: 100)
- ðŸï¸ Motocykl      (eco_points: 5)
- ðŸš• Taxi/Uber      (eco_points: 15)
```

### Zastosowania dla eko-mobilnoÅ›ci:

#### 1. System nagrÃ³d
```python
# Automatyczne punkty za transport
if mode == "public_transport":
    award_points(user, eco_points)
    check_badges(user)  # "Eco Warrior", "Public Transport Champion"

# Wyzwania
"Zero Carbon Week": 7 dni bez samochodu â†’ 500 bonus points
"Bike Month": 50km rowerem â†’ badge + zniÅ¼ka na bilety
```

#### 2. Tracking Å›ladu wÄ™glowego
```python
carbon_footprint = {
    "car": 120g CO2/km,
    "bus": 25g CO2/km,
    "tram": 15g CO2/km,
    "bike": 0g CO2/km,
    "walking": 0g CO2/km
}

# MiesiÄ™czny raport
monthly_savings = calculate_carbon_saved(user_trips)
city_ranking = get_eco_ranking(user)
```

#### 3. Gamifikacja
- **Rankingi**: Najlepsi eko-uÅ¼ytkownicy miasta
- **Wyzwania grupowe**: "Zielony dzielnica" competition
- **Nagrody**: ZniÅ¼ki, darmowe przejazdy, merchandise

#### 4. Analityka miejska
```python
# Agregowane dane
city_transport_mode_split = aggregate_all_users()
# "40% public transport, 25% car, 20% bike, 15% walking"

# Identyfikacja potrzeb
areas_needing_better_transit = analyze_patterns()
# "Dzielnica X: wysokie uÅ¼ycie aut â†’ potrzeba lepszego MPK"
```

### Architektura Transformera

```python
Input: [batch, seq_len=6000, features=15]  # 60s @ 100Hz
       â†“
Embedding Layer (project to d_model=128)
       â†“
Positional Encoding (temporal information)
       â†“
Transformer Encoder (6 layers, 8 heads)
  - Self-attention: KtÃ³re momenty sÄ… waÅ¼ne?
  - Feed-forward: Feature transformation
  - Layer norm + residual connections
       â†“
Global Average Pooling (seq â†’ single vector)
       â†“
Classification Head (11 classes)
       â†“
Output: [batch, 11] probability distribution

Metrics:
- Accuracy: >95% (vs ~85% XGBoost)
- F1-score: >0.93 per class
- Inference: <100ms
```

### ÅšcieÅ¼ka implementacji

1. **[OBECNIE]** Zbieranie danych z rule-based + ML validation
2. **[Q2]** Implementacja Transformer (PyTorch)
   - ZbiÃ³r danych: 10k+ podrÃ³Å¼y per klasa
   - Training: 4-8 GPU hours
   - Validation: Cross-validation + test set
3. **[Q3]** A/B testing
   - 10% ruchu â†’ Transformer
   - 90% ruchu â†’ XGBoost
   - Metryka: Accuracy + user feedback
4. **[Q3]** Produkcja
   - Deploy Transformer jeÅ›li lepszy o >5%
   - Monitoring + continuous learning
5. **[Q4]** Rozszerzenie multi-modal
   - Dodanie nowych klas transportu
   - Fine-tuning na nowych danych
6. **[Q1 next]** Gamifikacja
   - System punktÃ³w eco-mobility
   - Badges, rankingi, wyzwania
   - Integracja z reward system

---

## ðŸ“Š Dalsze kroki (krÃ³tkoterminowe)

1. **Zbieranie danych**: Cel 1000+ walidacji (sprawdÅº logi regularnie)
2. **Analiza zgodnoÅ›ci**: PorÃ³wnaj ML vs rule-based accuracy
3. **Feature importance**: KtÃ³re sensory sÄ… najwaÅ¼niejsze?
4. **Hyperparameter tuning**: Optymalizacja modelu XGBoost
5. **A/B test decision**: Czy wdroÅ¼yÄ‡ ML? (jeÅ›li accuracy >95%)
